{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../JasonMHoughton/Documents/Classwork/GWU MSBA/SUMMER 2017/Machine Learning/'\n",
    "train_file = (path+\"train.csv\")\n",
    "test_file = (path+\"test.csv\")\n",
    "output_file = (path+\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = np.loadtxt(train_file, skiprows=1, dtype='int', delimiter=',')\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    raw_data[:,1:], raw_data[:,0], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")/255.\n",
    "x_val = x_val.astype(\"float32\")/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31s - loss: 0.8877 - acc: 0.7210 - val_loss: 0.6071 - val_acc: 0.8350\n",
      "Epoch 2/20\n",
      "30s - loss: 0.3715 - acc: 0.8846 - val_loss: 0.0746 - val_acc: 0.9750\n",
      "Epoch 3/20\n",
      "30s - loss: 0.2904 - acc: 0.9146 - val_loss: 0.0778 - val_acc: 0.9825\n",
      "Epoch 4/20\n",
      "30s - loss: 0.2468 - acc: 0.9289 - val_loss: 0.0544 - val_acc: 0.9850\n",
      "Epoch 5/20\n",
      "37s - loss: 0.2150 - acc: 0.9381 - val_loss: 0.0513 - val_acc: 0.9825\n",
      "Epoch 6/20\n",
      "32s - loss: 0.1902 - acc: 0.9445 - val_loss: 0.0355 - val_acc: 0.9875\n",
      "Epoch 7/20\n",
      "32s - loss: 0.1710 - acc: 0.9533 - val_loss: 0.0398 - val_acc: 0.9875\n",
      "Epoch 8/20\n",
      "33s - loss: 0.1599 - acc: 0.9544 - val_loss: 0.0212 - val_acc: 0.9975\n",
      "Epoch 9/20\n",
      "35s - loss: 0.1558 - acc: 0.9552 - val_loss: 0.0327 - val_acc: 0.9850\n",
      "Epoch 10/20\n",
      "38s - loss: 0.1392 - acc: 0.9611 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 11/20\n",
      "31s - loss: 0.1261 - acc: 0.9637 - val_loss: 0.0241 - val_acc: 0.9900\n",
      "Epoch 12/20\n",
      "30s - loss: 0.1126 - acc: 0.9659 - val_loss: 0.0456 - val_acc: 0.9900\n",
      "Epoch 13/20\n",
      "30s - loss: 0.1297 - acc: 0.9619 - val_loss: 0.0146 - val_acc: 0.9975\n",
      "Epoch 14/20\n",
      "30s - loss: 0.1118 - acc: 0.9685 - val_loss: 0.0300 - val_acc: 0.9925\n",
      "Epoch 15/20\n",
      "30s - loss: 0.0896 - acc: 0.9724 - val_loss: 0.0170 - val_acc: 0.9925\n",
      "Epoch 16/20\n",
      "30s - loss: 0.1037 - acc: 0.9700 - val_loss: 0.0128 - val_acc: 0.9950\n",
      "Epoch 17/20\n",
      "30s - loss: 0.1002 - acc: 0.9704 - val_loss: 0.0152 - val_acc: 0.9925\n",
      "Epoch 18/20\n",
      "30s - loss: 0.1017 - acc: 0.9686 - val_loss: 0.0158 - val_acc: 0.9950\n",
      "Epoch 19/20\n",
      "31s - loss: 0.0916 - acc: 0.9729 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 20/20\n",
      "30s - loss: 0.0765 - acc: 0.9774 - val_loss: 0.0196 - val_acc: 0.9925\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
    "                           steps_per_epoch=500,\n",
    "                           epochs=20, \n",
    "                           verbose=2,  #1 for ETA, 0 for silent\n",
    "                           validation_data=(x_val[:400,:], y_val[:400,:]), #For speed\n",
    "                           callbacks=[annealer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.0302, final accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438   1   0   0   0   0   2   0   0   0]\n",
      " [  0 496   0   0   0   0   0   2   0   0]\n",
      " [  1   0 388   0   0   0   0   1   1   0]\n",
      " [  1   0   0 408   0   0   0   1   3   1]\n",
      " [  0   2   0   0 426   0   0   0   0   3]\n",
      " [  0   0   0   0   0 396   3   0   0   0]\n",
      " [  0   0   0   0   0   0 403   0   0   0]\n",
      " [  0   1   0   0   0   0   0 438   0   0]\n",
      " [  0   2   0   0   1   1   2   0 386   1]\n",
      " [  2   1   0   0   1   0   0   1   1 385]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(x_val)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_testset = np.loadtxt(test_file, skiprows=1, dtype='int', delimiter=',')\n",
    "x_test = mnist_testset.astype(\"float32\")\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_hat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as f :\n",
    "    f.write('ImageId,Label\\n')\n",
    "    for i in range(len(y_pred)) :\n",
    "        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
